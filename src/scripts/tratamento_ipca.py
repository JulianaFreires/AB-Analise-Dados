"""
Tratamento de Dados IPCA - IBGE

Este script realiza o tratamento dos dados do IPCA (√çndice de Pre√ßos ao Consumidor Amplo) 
do IBGE, incluindo limpeza, ordena√ß√£o e padroniza√ß√£o dos dados.

Autor: Sistema de An√°lise de Dados
Data: 2025-10-09
"""

import pandas as pd
import gzip
from io import StringIO
import os
from datetime import datetime


def setup_directories():
    """
    Configura e cria os diret√≥rios necess√°rios para o processamento
    """
    # Estrutura de diret√≥rios (Clean Architecture)
    base_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    
    directories = {
        'raw': os.path.join(base_dir, 'data', 'raw'),
        'processed': os.path.join(base_dir, 'data', 'processed'),
        'reports': os.path.join(base_dir, 'reports')
    }
    
    # Criando os diret√≥rios se n√£o existirem
    for name, path in directories.items():
        os.makedirs(path, exist_ok=True)
        print(f"üìÅ Diret√≥rio verificado: {path}")
    
    return directories


def verificar_arquivo_origem(directories):
    """
    Verifica a exist√™ncia do arquivo de dados IPCA
    """
    arquivo_original = os.path.join(directories['raw'], 'br_ibge_ipca_mes_brasil.csv.gz')
    
    if os.path.exists(arquivo_original):
        tamanho_mb = os.path.getsize(arquivo_original) / (1024 * 1024)
        print(f"‚úÖ Arquivo encontrado: {arquivo_original}")
        print(f"üìä Tamanho: {tamanho_mb:.2f} MB")
        return arquivo_original
    else:
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_original}")
        print("üí° Por favor, coloque o arquivo 'br_ibge_ipca_mes_brasil.csv.gz' na pasta 'data/raw/'")
        
        # Verificando se existe na raiz (para compatibilidade)
        arquivo_raiz = os.path.join(directories['raw'], '..', '..', 'br_ibge_ipca_mes_brasil.csv.gz')
        if os.path.exists(arquivo_raiz):
            print("üîÑ Encontrado arquivo na raiz do projeto - ser√° usado temporariamente")
            return arquivo_raiz
        
        return None


def carregar_e_tratar(nome_arquivo_comprimido):
    """
    Carrega e trata os dados do IPCA a partir de um arquivo .csv.gz
    
    Par√¢metros:
    nome_arquivo_comprimido (str): caminho do arquivo comprimido
    
    Retorna:
    pandas.DataFrame: dados tratados do IPCA
    """
    print(f"üîÑ Carregando dados de: {nome_arquivo_comprimido}")
    
    try:
        # Lendo o arquivo comprimido
        with gzip.open(nome_arquivo_comprimido, 'rt', encoding='utf-8') as arquivo:
            conteudo = arquivo.read()
        
        # Tratando valores nulos
        conteudo = conteudo.replace('..', '0')
        
        # Convertendo para DataFrame
        df = pd.read_csv(StringIO(conteudo))
        
        # Limpeza e formata√ß√£o dos dados
        df = df.dropna(how='all')  # Remove linhas completamente vazias
        
        # Converte colunas num√©ricas
        colunas_numericas = df.select_dtypes(include=['object']).columns
        for col in colunas_numericas:
            if col not in ['C√≥digo', 'M√™s', 'Local']:
                try:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                except:
                    pass
        
        # Ordena por ano e m√™s se as colunas existirem
        if 'Ano' in df.columns and 'M√™s' in df.columns:
            df = df.sort_values(['Ano', 'M√™s'])
        elif 'ano' in df.columns and 'mes' in df.columns:
            # ordenar por colunas min√∫sculas caso existam
            df = df.sort_values(['ano', 'mes'])

        # Garantir colunas Ano e Mes no formato esperado pelo pipeline de vendas
        # Aceitamos tanto 'Ano'/'M√™s' quanto 'ano'/'mes' e normalizamos para 'Ano' e 'Mes'
        if 'Ano' in df.columns and 'M√™s' in df.columns:
            # converter nomes com acento e tipos
            try:
                df['Ano'] = pd.to_numeric(df['Ano'], errors='coerce').astype('Int64')
            except Exception:
                pass
            try:
                df['Mes'] = pd.to_numeric(df['M√™s'], errors='coerce').astype('Int64')
            except Exception:
                pass
        elif 'ano' in df.columns and 'mes' in df.columns:
            df['Ano'] = pd.to_numeric(df['ano'], errors='coerce').astype('Int64')
            df['Mes'] = pd.to_numeric(df['mes'], errors='coerce').astype('Int64')
        else:
            # tenta detectar colunas poss√≠veis alternativas (ex: 'year','month')
            ano_col = next((c for c in df.columns if c.lower() in ['ano', 'year']), None)
            mes_col = next((c for c in df.columns if c.lower() in ['mes', 'm√™s', 'month']), None)
            if ano_col:
                df['Ano'] = pd.to_numeric(df[ano_col], errors='coerce').astype('Int64')
            if mes_col:
                df['Mes'] = pd.to_numeric(df[mes_col], errors='coerce').astype('Int64')

        # Criar campo Ano_Mes no formato YYYYMM (inteiro) se poss√≠vel
        if 'Ano' in df.columns and 'Mes' in df.columns:
            # Preencher valores faltantes com 0 antes do c√°lculo √© indesej√°vel; remover linhas sem Ano/Mes
            df = df.dropna(subset=['Ano', 'Mes']).copy()
            # garantir inteiros
            df['Ano'] = df['Ano'].astype(int)
            df['Mes'] = df['Mes'].astype(int)
            df['Ano_Mes'] = df['Ano'] * 100 + df['Mes']
            # garantir tipo inteiro
            df['Ano_Mes'] = df['Ano_Mes'].astype(int)
            print("   ‚úÖ Campo Ano_Mes criado no formato YYYYMM")
        else:
            print("   ‚ö†Ô∏è N√£o foi poss√≠vel criar Ano_Mes: colunas Ano e/ou Mes n√£o encontradas")
        
        print(f"‚úÖ Dados carregados: {len(df)} registros")
        print(f"üìã Colunas: {list(df.columns)}")
        
        return df
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar dados: {e}")
        return None


def analise_exploratoria(df):
    """
    Realiza an√°lise explorat√≥ria dos dados IPCA
    
    Par√¢metros:
    df (pandas.DataFrame): DataFrame com dados do IPCA
    """
    print("\nüìä AN√ÅLISE EXPLORAT√ìRIA DOS DADOS IPCA")
    print("=" * 60)
    
    # Informa√ß√µes gerais
    print(f"üìà N√∫mero de registros: {len(df):,}")
    print(f"üìã N√∫mero de colunas: {len(df.columns)}")
    print(f"üè∑Ô∏è  Colunas: {list(df.columns)}")
    
    # Verificando valores nulos
    print(f"\nüîç Valores nulos por coluna:")
    nulos = df.isnull().sum()
    for col, count in nulos.items():
        if count > 0:
            print(f"   {col}: {count:,} ({count/len(df)*100:.1f}%)")
        else:
            print(f"   {col}: ‚úÖ Sem valores nulos")
    
    # Informa√ß√µes sobre tipos de dados
    print(f"\nüî¢ Tipos de dados:")
    for col, dtype in df.dtypes.items():
        print(f"   {col}: {dtype}")
    
    # Estat√≠sticas descritivas para colunas num√©ricas
    colunas_numericas = df.select_dtypes(include=['int64', 'float64']).columns
    if len(colunas_numericas) > 0:
        print(f"\nüìä Estat√≠sticas descritivas:")
        stats = df[colunas_numericas].describe()
        print(stats)
        
        # Informa√ß√µes sobre o per√≠odo dos dados
        if 'Ano' in df.columns:
            ano_min = df['Ano'].min()
            ano_max = df['Ano'].max()
            print(f"\nüìÖ Per√≠odo dos dados: {ano_min} a {ano_max}")
    
    return nulos, stats if len(colunas_numericas) > 0 else None


def salvar_dados_tratados(df, directories):
    """
    Salva os dados tratados em arquivo CSV
    
    Par√¢metros:
    df (pandas.DataFrame): DataFrame com dados tratados
    directories (dict): Dicion√°rio com caminhos dos diret√≥rios
    """
    arquivo_tratado = os.path.join(directories['processed'], 'ipca_processado.csv')
    try:
        # Salvar apenas o arquivo principal (sem criar backups autom√°ticos)
        df.to_csv(arquivo_tratado, index=False, encoding='utf-8')
        print(f"‚úÖ Dados salvos em: {arquivo_tratado}")

        # Verificar tamanho do arquivo salvo
        tamanho_principal = os.path.getsize(arquivo_tratado) / (1024 * 1024)
        print(f"üìä Tamanho do arquivo: {tamanho_principal:.2f} MB")

        # Verifica√ß√£o da integridade dos dados salvos
        df_verificacao = pd.read_csv(arquivo_tratado, nrows=3)
        print(f"\nüîç Verifica√ß√£o - Primeiras 3 linhas do arquivo salvo:")
        print(df_verificacao)

        # Retornamos None no lugar do backup para compatibilidade
        return arquivo_tratado, None

    except Exception as e:
        print(f"‚ùå Erro ao salvar arquivo: {e}")
        return None, None


def main():
    """
    Fun√ß√£o principal que executa todo o pipeline de tratamento dos dados IPCA
    """
    print("üöÄ INICIANDO TRATAMENTO DE DADOS IPCA - IBGE")
    print("=" * 60)
    
    # 1. Configurar diret√≥rios
    directories = setup_directories()
    
    # 2. Verificar arquivo de origem
    arquivo_original = verificar_arquivo_origem(directories)
    
    if not arquivo_original:
        print("‚ùå N√£o foi poss√≠vel localizar o arquivo de dados. Processo interrompido.")
        return None
    
    # 3. Carregar e tratar dados
    df_ipca = carregar_e_tratar(arquivo_original)
    
    if df_ipca is None:
        print("‚ùå Falha no carregamento dos dados. Processo interrompido.")
        return None
    
    # 4. An√°lise explorat√≥ria
    nulos, stats = analise_exploratoria(df_ipca)
    
    # 5. Salvar dados tratados
    arquivo_principal, arquivo_backup = salvar_dados_tratados(df_ipca, directories)
    
    if arquivo_principal:
        print("\n" + "=" * 60)
        print("‚úÖ PROCESSAMENTO CONCLU√çDO COM SUCESSO!")
        print(f"üìÅ Arquivo principal: {arquivo_principal}")
        print(f"üíæ Arquivo backup: {arquivo_backup}")
        print(f"üìä Total de registros processados: {len(df_ipca):,}")
        print("üéØ Dados prontos para an√°lise!")
    else:
        print("‚ùå Falha na finaliza√ß√£o do processamento.")
    
    return df_ipca


if __name__ == "__main__":
    # Executar o processamento principal
    dados_ipca = main()